{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ylmHRNZuexnE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "105684d7-92a3-4023-bc05-2fc9d6893e5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.7/727.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.0/190.0 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# install pytorch lithening\n",
        "!pip install pytorch-lightning --quiet\n",
        "!pip install wandb --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5dPxEJZwe6Y2"
      },
      "outputs": [],
      "source": [
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader,random_split\n",
        "from torchmetrics import Accuracy\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "import wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CczgZ5nkgAGy"
      },
      "outputs": [],
      "source": [
        "# create one class to deal with data\n",
        "class CifarDataModule(pl.LightningDataModule):\n",
        "  def __init__(self, batch_size, data_dir=\"./\"):\n",
        "    super().__init__()\n",
        "    self.data_dir=data_dir\n",
        "    self.batch_size=batch_size\n",
        "    self.transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
        "    self.num_classes=10\n",
        "\n",
        "  def prepare_data(self):\n",
        "    CIFAR10(self.data_dir,train=True,download=True)\n",
        "    CIFAR10(self.data_dir,train=False,download=True)\n",
        "\n",
        "  def setup(self, stage=None):\n",
        "    if stage=='fit' or stage is None:\n",
        "      cifar_full=CIFAR10(self.data_dir,train=True,transform=self.transform)\n",
        "      self.cifar_train,self.cifar_val=random_split(cifar_full,[45000,5000])\n",
        "\n",
        "    if stage=='test' or stage is None:\n",
        "      self.cifar_test=CIFAR10(self.data_dir,train=False,transform=self.transform)\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(self.cifar_train,batch_size=self.batch_size,shuffle=True,num_workers=2)\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(self.cifar_val,batch_size=self.batch_size,shuffle=False,num_workers=2)\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    return DataLoader(self.test_dataloader,batch_size=self.batch_size,shuffle=False,num_workers=2)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Xal7kSzlkAb"
      },
      "outputs": [],
      "source": [
        "class CIFAR10LitModel(pl.LightningModule):\n",
        "    def __init__(self, input_shape,num_classes,learning_rate=3e-4):\n",
        "      super().__init__()\n",
        "      self.save_hyperparameters()\n",
        "      self.input_shape=input_shape\n",
        "      self.learning_rate=learning_rate\n",
        "\n",
        "      # model architecture\n",
        "      self.conv1=nn.Conv2d(3,32,3,1)\n",
        "      self.conv2=nn.Conv2d(32,32,3,1)\n",
        "      self.conv3=nn.Conv2d(32,64,3,1)\n",
        "      self.conv4=nn.Conv2d(64,64,3,1)\n",
        "      self.pool1=nn.MaxPool2d(2)\n",
        "      self.pool2=nn.MaxPool2d(2)\n",
        "\n",
        "      n_sizes = self._get_output_shape(input_shape)\n",
        "      self.fc1=nn.Linear(n_sizes,512)\n",
        "      self.fc2=nn.Linear(512,128)\n",
        "      self.fc3=nn.Linear(128,num_classes)\n",
        "\n",
        "      self.train_acc=Accuracy(task='multiclass',num_classes=10)\n",
        "      self.val_acc=Accuracy(task='multiclass',num_classes=10)\n",
        "      self.test_acc=Accuracy(task='multiclass',num_classes=10)\n",
        "\n",
        "\n",
        "    def _get_output_shape(self, shape):\n",
        "          '''returns the size of the output tensor from the conv layers'''\n",
        "          batch_size = 1\n",
        "          input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
        "          output_feat = self._feature_extractor(input)\n",
        "          n_size = output_feat.data.view(batch_size, -1).size(1)\n",
        "          return n_size\n",
        "\n",
        "\n",
        "  # conv1,relu, conv2,relu, maxpool,conv3,relu,conv4,relu,maxpool\n",
        "    def _feature_extractor(self,x):\n",
        "      x=F.relu(self.conv1(x))\n",
        "      x=self.pool1(F.relu(self.conv2(x)))\n",
        "      x=F.relu(self.conv3(x))\n",
        "      x=self.pool2(F.relu(self.conv4(x)))\n",
        "      return x\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "      x=self._feature_extractor(x)\n",
        "      x=x.view(x.size(0),-1)\n",
        "      x=F.relu(self.fc1(x))\n",
        "      x=F.relu(self.fc2(x))\n",
        "      x=F.log_softmax(self.fc3(x),dim=1)\n",
        "      return x\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "      x, y = batch\n",
        "      logits = self(x)\n",
        "      loss = F.nll_loss(logits, y)\n",
        "      # metric\n",
        "      preds = torch.argmax(logits, dim=1)\n",
        "      acc = self.train_acc(preds, y)\n",
        "      self.log('train_loss', loss, on_step=True, on_epoch=True, logger=True)\n",
        "      self.log('train_acc', acc, on_step=True, on_epoch=True, logger=True)\n",
        "      return loss\n",
        "\n",
        "    # validation loop\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "      x, y = batch\n",
        "      logits = self(x)\n",
        "      loss = F.nll_loss(logits, y)\n",
        "      preds = torch.argmax(logits, dim=1)\n",
        "      acc = self.val_acc(preds, y)\n",
        "      self.log('val_loss', loss, prog_bar=True)\n",
        "      self.log('val_acc', acc, prog_bar=True)\n",
        "      return loss\n",
        "\n",
        "    # test loop\n",
        "    def test_step(self,batch,batch_idx):\n",
        "      x,y=batch\n",
        "      logits=self(x)\n",
        "      loss=F.nll_loss(logits,y)\n",
        "\n",
        "      pred=torch.argmax(logits,dim=1)\n",
        "      acc=self.test_acc(pred,y)\n",
        "      self.log('test_loss',loss,on_epoch=True)\n",
        "      self.log('test_acc',acc,on_epoch=True)\n",
        "      return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "      optimizer=torch.optim.Adam(self.parameters(),self.learning_rate)\n",
        "      return optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRAcw-MZYebS"
      },
      "outputs": [],
      "source": [
        "# class for visualizing one batch of validation images along with predicted and rall class label\n",
        "class ImagePredictionLogger(pl.Callback):\n",
        "    def __init__(self, val_samples, num_samples=32):\n",
        "        super().__init__()\n",
        "        self.val_imgs, self.val_labels = val_samples\n",
        "        self.val_imgs = self.val_imgs[:num_samples]\n",
        "        self.val_labels = self.val_labels[:num_samples]\n",
        "\n",
        "    def on_validation_epoch_end(self, trainer, pl_module):\n",
        "        val_imgs = self.val_imgs.to(device=pl_module.device)\n",
        "        logits = pl_module(val_imgs)\n",
        "        preds = torch.argmax(logits, 1)\n",
        "\n",
        "        trainer.logger.experiment.log({\n",
        "            \"examples\": [wandb.Image(x, caption=f\"Pred:{pred}, Label:{y}\")\n",
        "                            for x, pred, y in zip(val_imgs, preds, self.val_labels)],\n",
        "            \"global_step\": trainer.global_step\n",
        "            })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7kOEzHpmCYi",
        "outputId": "069d29f7-18bd-4e7d-ae29-d6da71b9e2f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "cifar = CifarDataModule(batch_size=32)\n",
        "cifar.prepare_data()\n",
        "cifar.setup()\n",
        "# grab samples to log predictions on\n",
        "samples = next(iter(cifar.val_dataloader()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbTicSoZ1Gtw"
      },
      "outputs": [],
      "source": [
        "### WandB, you have have an account(if you don't, create one)\n",
        "def train_model(learning_rate=1e-3):\n",
        "    wandb.login(key='copy your api key here')\n",
        "    config=wandb.config\n",
        "    wandb_logger = WandbLogger(project='lastt', job_type='train', log_model=\"all\")\n",
        "    # instantiate classes\n",
        "    dm = CifarDataModule(32)\n",
        "    dm.prepare_data()\n",
        "    dm.setup()\n",
        "    model = CIFAR10LitModel((3, 32, 32), dm.num_classes, learning_rate)\n",
        "    wandb_logger.watch(model)\n",
        "    # Initialize Callbacks\n",
        "    checkpoint_callback = pl.callbacks.ModelCheckpoint()\n",
        "    early_stop_callback = pl.callbacks.EarlyStopping(monitor=\"val_acc\", patience=3, verbose=False, mode=\"max\")\n",
        "    ### WandB\n",
        "    trainer = pl.Trainer(max_epochs=5,\n",
        "                     logger=wandb_logger,\n",
        "                     callbacks=[checkpoint_callback, early_stop_callback,ImagePredictionLogger(samples)]\n",
        "                    )\n",
        "    # Train the model\n",
        "    trainer.fit(model, dm)\n",
        "\n",
        "    # Evaluate the model\n",
        "    trainer.test(dataloaders=cifar.test_dataloader())\n",
        "    # tell the WandB you have finished\n",
        "    wandb.finish()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "edXZVgxLd7_b"
      },
      "outputs": [],
      "source": [
        "train_model()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}